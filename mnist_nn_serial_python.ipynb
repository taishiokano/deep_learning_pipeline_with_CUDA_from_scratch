{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7jnKCrjiWjp"
   },
   "source": [
    "# 1 Intro: Basic Curve Fitting with Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sStzwwaidpa"
   },
   "source": [
    "## Setting\n",
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-rHOeTWQf-03"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "n = 20\n",
    "alpha = 0.01\n",
    "epsilon = 0.1 ** 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qvgnXpsh_Hy"
   },
   "source": [
    "### Make initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4qMM4pqBh8yt",
    "outputId": "c7b9d81a-f2e9-428a-de69-24fc0952a69d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  [0.6394267984578837, 0.27502931836911926, 0.7364712141640124, 0.8921795677048454, 0.4219218196852704, 0.21863797480360336, 0.026535969683863625, 0.6498844377795232, 0.2204406220406967, 0.8094304566778266, 0.8058192518328079, 0.3402505165179919, 0.9572130722067812, 0.09274584338014791, 0.8474943663474598, 0.8071282732743802, 0.5362280914547007, 0.3785343772083535, 0.8294046642529949, 0.8617069003107772]\n",
      "y:  [0.025010755222666936, 0.22321073814882275, 0.6766994874229113, 0.08693883262941615, 0.029797219438070344, 0.5053552881033624, 0.1988376506866485, 0.5449414806032167, 0.5892656838759087, 0.006498759678061017, 0.6981393949882269, 0.15547949981178155, 0.33659454511262676, 0.09671637683346401, 0.6037260313668911, 0.7297317866938179, 0.9731157639793706, 0.552040631273227, 0.6185197523642461, 0.577352145256762]\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "x = []\n",
    "y = []\n",
    "for i in range(n):\n",
    "    x.append(random.random())\n",
    "    y.append(random.random())\n",
    "print(\"x: \", x)\n",
    "print(\"y: \", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UHeSzf2itmG"
   },
   "source": [
    "### Guess m and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9eRQhcRh8wF",
    "outputId": "835c2f30-5cbe-46b1-e763-11a8fd036a02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:  0.5   b:  0\n"
     ]
    }
   ],
   "source": [
    "m = 0.5\n",
    "b = 0\n",
    "print(\"m: \", m, \"  b: \", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GAIGz7oizVB"
   },
   "source": [
    "## Gradient Descent Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFouWWyQh8uC",
    "outputId": "60cb6dc7-108e-4a3a-8f4d-74446e1f8751"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:  0.23606845773749743   b:  0.27746866427140193\n"
     ]
    }
   ],
   "source": [
    "detected = False\n",
    "while not detected:\n",
    "    delta_m = 0\n",
    "    delta_b = 0\n",
    "    for i in range(n):\n",
    "        delta_m += (2*b*x[i] + 2*m*(x[i] ** 2) - 2*x[i]*y[i])\n",
    "        delta_b += (2*b + 2*m*x[i] - 2*y[i])\n",
    "    delta_m = delta_m / n\n",
    "    delta_b = delta_b / n\n",
    "    m -= alpha * delta_m\n",
    "    b -= alpha * delta_b\n",
    "    if math.sqrt(delta_m**2 + delta_b**2) < epsilon:\n",
    "        detected = True\n",
    "\n",
    "print(\"m: \", m, \"  b: \", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHpnQkj3lnwW"
   },
   "source": [
    "## Scikit-learn Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zjwCCPTwlnR5",
    "outputId": "9e8047fb-a35a-4937-b132-9979820c8633"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: [0.2359993]\n",
      "b: [0.27751048]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mod = LinearRegression()\n",
    "df_x = pd.DataFrame(x)\n",
    "df_y = pd.DataFrame(y)\n",
    "mod_lin = mod.fit(df_x, df_y)\n",
    "print('m:', mod.coef_[0]) \n",
    "print('b:', mod.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQGGjKdmoA6_"
   },
   "source": [
    "We can confirm that the answers are almost the same in both processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNihfTdLnn07"
   },
   "source": [
    "# 2 Building and Training a Neural Network for Rasterized Digit Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwLvk7T7v7IR"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fzWgxPmtv6n6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 60000   rows: 28   cols: 28\n"
     ]
    }
   ],
   "source": [
    "# Reference: https://github.com/sorki/python-mnist/blob/master/mnist/loader.py\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "train_image_path = './data/train-images-idx3-ubyte'\n",
    "train_label_path = './data/train-labels-idx1-ubyte'\n",
    "test_image_path = './data/t10k-images-idx3-ubyte'\n",
    "test_label_path = './data/t10k-labels-idx1-ubyte'\n",
    "with open(train_label_path, 'rb') as file:\n",
    "    magic, size = struct.unpack(\">II\", file.read(8)) # 使わないけど読み込んどかないとlabalsに余計なものが読み込まれちゃう。\n",
    "    labels = file.read()\n",
    "with open(train_image_path, 'rb') as file:\n",
    "    magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "    image_data = file.read()\n",
    "print(\"size:\", size, '  rows:', rows, '  cols:', cols)\n",
    "images = []\n",
    "for i in range(size):\n",
    "    images.append([0] * rows * cols)\n",
    "    images[i][:] = image_data[i * rows * cols:(i + 1) * rows * cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 10000   rows: 28   cols: 28\n"
     ]
    }
   ],
   "source": [
    "with open(test_label_path, 'rb') as file:\n",
    "    magic, size_test = struct.unpack(\">II\", file.read(8))\n",
    "    labels_test = file.read()\n",
    "with open(test_image_path, 'rb') as file:\n",
    "    magic, size_test, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "    image_data_test = file.read()\n",
    "print(\"size:\", size_test, '  rows:', rows, '  cols:', cols)\n",
    "images_test = []\n",
    "for i in range(size_test):\n",
    "    images_test.append([0] * rows * cols)\n",
    "    images_test[i][:] = image_data_test[i * rows * cols:(i + 1) * rows * cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for i in range(size):\n",
    "    label_onehot = [0] * 10\n",
    "    label_onehot[labels[i]] = 1\n",
    "    train.append([np.reshape(images[i], (-1,1)), np.reshape(label_onehot, (-1,1))])\n",
    "test = []\n",
    "for i in range(size_test):\n",
    "    label_onehot = [0] * 10\n",
    "    label_onehot[labels_test[i]] = 1\n",
    "    test.append([np.reshape(images_test[i], (-1,1)), np.reshape(label_onehot, (-1,1))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   51 159 253 159  50  0   0   0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   48 238 252 252 252 237  0   0   0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   54 227 253 252 239 233 252  57  6   0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0   0   0   0   0   10  60 224 252 253 252 202  84 252 253 122  0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0   0   0   0   0  163 252 252 252 253 252 252  96 189 253 167  0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0   0   0   0   51 238 253 253 190 114 253 228  47  79 255 168  0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0   0   0   48 238 252 252 179  12  75 121  21  0   0  253 243  50  0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0   0   38 165 253 233 208  84  0   0   0   0   0   0  253 252 165  0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0   7  178 252 240  71  19  28  0   0   0   0   0   0  253 252 195  0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0   57 252 252  63  0   0   0   0   0   0   0   0   0  253 252 195  0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0  198 253 190  0   0   0   0   0   0   0   0   0   0  255 253 196  0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   76 246 252 112  0   0   0   0   0   0   0   0   0   0  253 252 148  0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   85 252 230  25  0   0   0   0   0   0   0   0   7  135 253 186  12  0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   85 252 223  0   0   0   0   0   0   0   0   7  131 252 225  71  0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   85 252 145  0   0   0   0   0   0   0   48 165 252 173  0   0   0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   86 253 225  0   0   0   0   0   0  114 238 253 162  0   0   0   0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   85 252 249 146  48  29  85 178 225 253 223 167  56  0   0   0   0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   85 252 252 252 229 215 252 252 252 196 130  0   0   0   0   0   0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   28 199 252 252 253 252 252 233 145  0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0   25 128 252 253 252 141  37  0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      "\n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      "\n",
      "Label:  0\n"
     ]
    }
   ],
   "source": [
    "# As numbers\n",
    "img_num = 1\n",
    "for idx, val in enumerate(images[img_num]):\n",
    "    if idx%28==0:\n",
    "        print('\\n')\n",
    "    print(str(val).center(3), end=' ')\n",
    "print('\\n\\nLabel: ', labels[img_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def mnist_digit_show(flatimage, outname=None):\n",
    "    image = np.reshape(flatimage, (28, 28))\n",
    "    plt.matshow(image, cmap=plt.cm.binary)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if outname:\n",
    "        plt.savefig(outname)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPEAAAD0CAYAAABKBsC6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAG/UlEQVR4nO3dT4jN+x/H8Rnjv7jIb4FEUbdE/nRkoVwsrtX1Z6duxOJm4c/GJLJgcVfs/KkbFrK4SmIxK13F4qY0RyS3rm4KWdDvJhYsSOe3tRjv49yZ+ZnXncdj+5oZ34anz9Snc6a71Wp1AbnGfO0HAAZHxBBOxBBOxBBOxBBOxBBOxBBOxBBOxBBubCcfPGvWrNaCBQuG6VGAz3ny5EnX33//3T3Q1lHECxYs6Go2m0PzVMAXazQan938OA3hRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhRAzhxn7tB+DLffz4sdzfvHkzrH/+6dOny/3du3fl/ujRo3I/c+ZMuff29pb7pUuXyn3ixInlfujQoXI/evRouX8tTmIIJ2IIJ2IIJ2IIJ2IIJ2IIJ2II5564A8+ePSv39+/fl/vt27fL/ffffy/3169fl/uVK1fK/WubN29eue/bt6/cr127Vu5Tp04t92XLlpX7d999V+4jlZMYwokYwokYwokYwokYwokYwokYwrkn/sS9e/fKfcOGDeU+3K/nHel6enrK/eeffy73KVOmlPuPP/5Y7nPmzCn3GTNmlPu3335b7iOVkxjCiRjCiRjCiRjCiRjCiRjCiRjCuSf+xPz588t91qxZ5T7S74lXr15d7u3uUW/evFnu48ePL/ft27eXO/+MkxjCiRjCiRjCiRjCiRjCiRjCiRjCuSf+xMyZM8v9xIkT5d7X11fuK1asKPf9+/eXezvLly8v9xs3bpR7u9fzPnz4sNxPnjxZ7gwPJzGEEzGEEzGEEzGEEzGEEzGEEzGEc0/cgS1btpR7u/elbvf7cx88eFDu58+fL/fe3t5yb3cP3M6SJUvK/ezZs4P6+vwzTmIIJ2IIJ2IIJ2IIJ2IIJ2IIJ2II5554CE2bNm1Qn//NN98M6vPb3SNv27at3MeM8X96In9rEE7EEE7EEE7EEE7EEE7EEE7EEM498Qhy7Nixcr97926537p1q9zbve/0999/X+6MTE5iCCdiCCdiCCdiCCdiCCdiCCdiCOeeeARp977Q586dK/eVK1eW+08//VTu69evL/dGo1Hue/bsKffu7u5y559xEkM4EUM4EUM4EUM4EUM4EUM4EUM498RBFi5cWO4XLlwo9127dpX7xYsXB7W/ffu23Hfs2FHus2fPLncG5iSGcCKGcCKGcCKGcCKGcCKGcCKGcO6J/0W2bt1a7osWLSr3AwcOlHu7960+fPhwuT99+rTcjxw5Uu5z584t99HKSQzhRAzhRAzhRAzhRAzhRAzhRAzh3BOPIkuXLi33y5cvl3tfX1+579y5s9x/+eWXcv/rr7/K/bfffiv30cpJDOFEDOFEDOFEDOFEDOFEDOFEDOG6W63WF39wo9FoNZvNYXwckk2YMKHcP3z4UO7jxo0r9+vXr5f7unXryj1Zo9HoajabA/6CZycxhBMxhBMxhBMxhBMxhBMxhBMxhPN64lHkwYMH5X7lypVy7+/vL/d298DtLF68uNzXrl07qK//b+UkhnAihnAihnAihnAihnAihnAihnDuiYM8evSo3E+dOlXuV69eLfcXL150/EydGDu2/uc2e/bsch8zxpkzEN8VCCdiCCdiCCdiCCdiCCdiCCdiCOee+P+o3T3sr7/+Wu6nT58u9ydPnnT6SENq1apV5X7kyJFy37Rp01A+zqjhJIZwIoZwIoZwIoZwIoZwIoZwIoZw7ok78PLly3L/448/yn3v3r3l/ueff3b8TENp9erV5X7w4MFy37x5c7l7PfDw8F2FcCKGcCKGcCKGcCKGcCKGcCKGcKPqnvjVq1flvnv37nK/f/9+uT9+/LjTRxpSa9asKfcDBw6U+8aNG8t90qRJHT8Tw89JDOFEDOFEDOFEDOFEDOFEDOFEDOGi7onv3LlT7sePHy/3/v7+cn/+/HnHzzSUJk+eXO779+8v93bv6zxlypSOn4mRz0kM4UQM4UQM4UQM4UQM4UQM4UQM4aLuia9duzaofbAWL15c7j/88EO59/T0lHtvb2+5T58+vdwZnZzEEE7EEE7EEE7EEE7EEE7EEE7EEK671Wp98Qc3Go1Ws9kcxscBBtJoNLqazWb3QJuTGMKJGMKJGMKJGMKJGMKJGMKJGMKJGMKJGMKJGMKJGMKJGMKJGMKJGMKJGMKJGMKJGMKJGMKJGMKJGMKJGMKJGMKJGMJ19L7T3d3d/+3q6no6fI8DfMb8Vqv1n4GGjiIGRh4/TkM4EUM4EUM4EUM4EUM4EUM4EUM4EUM4EUO4/wHZmAaSsnjjmAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_digit_show(images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "location = './debugdata/tinyMNIST.pkl.gz'\n",
    "f = gzip.open(location, 'rb')\n",
    "u = pickle._Unpickler(f)\n",
    "u.encoding = 'latin1'\n",
    "train, test = u.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lf1Wgf14v-Hz"
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs\n",
    "\n",
    "- nl: number of dense (fully connected) linear layers in your NN (excluding the first and last layers)\n",
    "- nh: numnber of units in each of the hidden layers\n",
    "- ne: number of training epochs\n",
    "- nb: number of training samples per batch\n",
    "- alpha: learning rate\n",
    "- lam: Regularization parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nl = 2\n",
    "# nh = 30\n",
    "# ne = 10000\n",
    "# nb = 6000\n",
    "# alpha = 0.1\n",
    "# lam = 0.0001\n",
    "# output_type = 0\n",
    "\n",
    "nl = 2\n",
    "nh = 30\n",
    "ne = 20000\n",
    "nb = 10\n",
    "alpha = 0.1\n",
    "lam = 0.0001\n",
    "output_type = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "H0IoObOoh8rp"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "layers = [train[0][0].shape[0]] + [nh]*nl + [train[0][1].shape[0]]\n",
    "L = len(layers)\n",
    "# biases = [np.random.randn(n, 1) for n in layers[1:]] # input layer以外で必要. sizeが((30,1),(30,1),(10,1))のlist of lists.\n",
    "biases = [np.zeros((n, 1)) for n in layers[1:]] # input layer以外で必要. sizeが((30,1),(30,1),(10,1))のlist of lists.\n",
    "weights = [np.random.randn(n, m) for (m, n) in zip(layers[:-1], layers[1:])] # ((784,30),(30,30),(30,10)). 長さmの縦長行列を長さnに変換する。\n",
    "deltas = [[np.zeros((n, 1)) for n in layers]] * nb # ((784,1),(30,1),(30,1),(10,1)) x 300\n",
    "z_list = [[np.zeros((n, 1)) for n in layers]] * nb # ((784,1),(30,1),(30,1),(10,1)) x 300. input layerは不要だけど簡単化のためつけている。\n",
    "a_list = [[np.zeros((n, 1)) for n in layers]] * nb # ((784,1),(30,1),(30,1),(10,1)) x 300\n",
    "\n",
    "def SGD_train(train, ne, nb, alpha, lam = 0.0, log_interval=10, test=None):\n",
    "    \"\"\"SGD for training parameters\n",
    "    If verbose is set, print progressive accuracy updates.\n",
    "    If test set is provided, routine will print accuracy on test set as learning evolves\n",
    "    \"\"\"\n",
    "    for epoch in range(ne):\n",
    "        if epoch % log_interval == 0:\n",
    "            log_train_progress(train, test, epoch)\n",
    "        batch = random.sample(range(0, len(train)), nb)\n",
    "        for s, sample in enumerate(batch):\n",
    "            forward_back_prop(train[sample][0], train[sample][1], s)\n",
    "        for l in range(L-1):\n",
    "            for s in range(nb):\n",
    "                biases[l] -= (alpha/nb) * deltas[s][l+1]\n",
    "                weights[l] -= (alpha/nb) * np.dot(deltas[s][l+1], a_list[s][l].T)\n",
    "    log_train_progress(train, test, ne)\n",
    "\n",
    "def forward_back_prop(x, y, s):\n",
    "    \"\"\"Forward & back propagation for derivatives of C wrt parameters\"\"\"\n",
    "    a_list[s][0] = x\n",
    "\n",
    "    # Feedforward\n",
    "    for l in range(1, L):\n",
    "        z_list[s][l] = np.dot(weights[l-1], a_list[s][l-1]) + biases[l-1]\n",
    "        if l == L-1 and output_type == 0:\n",
    "            a_list[s][l] = softmax(z_list[s][l])\n",
    "        else:\n",
    "            a_list[s][l] = sigmoid(z_list[s][l])\n",
    "\n",
    "    # Output Error\n",
    "    if output_type == 1:\n",
    "        deltas[s][L-1] = grad_cost(a_list[s][L-1], y) * sigmoid_prime(z_list[s][L-1])\n",
    "    else:\n",
    "        deltas[s][L-1] = delta_cross_entropy(a_list[s][L-1], y)\n",
    "\n",
    "    # Back propagate\n",
    "    for l in range(L-2, -1, -1): # layerはoutputの後から遡っていく。L=4ならlayer=2,1,0\n",
    "        deltas[s][l] = np.dot(weights[l].T, deltas[s][l+1]) * sigmoid_prime(z_list[s][l])\n",
    "        # l=2の時、deltas[s][l]は(30, 1), weights[l].Tは(30, 10), deltas[s][l+1]は(10, 1), z_list[s][l]は(30, 1)\n",
    "\n",
    "def grad_cost(a, y):\n",
    "    \"\"\"gradient of cost function. Assumes C(a,y) = (a-y)^2/2\"\"\"\n",
    "    return (a - y)\n",
    "\n",
    "def sigmoid(z, threshold=20):\n",
    "    z = np.clip(z, -threshold, threshold)\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z) * (1.0 - sigmoid(z))\n",
    "\n",
    "def softmax(z, overflow=False):\n",
    "    exp_z = np.exp(z)\n",
    "    if overflow:\n",
    "        exp_z = np.exp(z - np.max(z))\n",
    "    return exp_z / np.sum(exp_z)\n",
    "\n",
    "def delta_cross_entropy(p, y):\n",
    "    return (p - y)\n",
    "\n",
    "def forward_prop(a):\n",
    "    \"\"\"forward propagation for evaluate function only\"\"\"\n",
    "    for w, b in zip(weights, biases):\n",
    "        z = np.dot(w, a) + b\n",
    "        a = sigmoid(z)\n",
    "    return a\n",
    "\n",
    "def evaluate(data):\n",
    "    \"\"\"Evaluate current model on labeled train/test data\"\"\"\n",
    "    ctr = 0\n",
    "    for x, y in data:\n",
    "        yhat = forward_prop(x)\n",
    "        ctr += yhat.argmax() == y.argmax()\n",
    "    return float(ctr) / float(len(data))\n",
    "\n",
    "def log_train_progress(train, test, epoch):\n",
    "    \"\"\"Logs training progress\"\"\"\n",
    "    acc_train = evaluate(train)\n",
    "    if test is not None:\n",
    "        acc_test = evaluate(test)\n",
    "        print(\"Epoch {:4d}: Train {:10.5f}, Test {:10.5f}\".format(epoch, acc_train, acc_test))\n",
    "    else:\n",
    "        print(\"Epoch {:4d}: Train {:10.5f}\".format(epoch, acc_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0: Train    0.09924, Test    0.09844\n",
      "Epoch 1000: Train    0.59704, Test    0.52861\n",
      "Epoch 2000: Train    0.79672, Test    0.69508\n",
      "Epoch 3000: Train    0.81192, Test    0.71068\n",
      "Epoch 4000: Train    0.86715, Test    0.76110\n",
      "Epoch 5000: Train    0.85314, Test    0.73870\n",
      "Epoch 6000: Train    0.82513, Test    0.71789\n",
      "Epoch 7000: Train    0.87155, Test    0.76991\n",
      "Epoch 8000: Train    0.91236, Test    0.81192\n",
      "Epoch 9000: Train    0.86515, Test    0.75350\n",
      "Epoch 10000: Train    0.87315, Test    0.75870\n",
      "Epoch 11000: Train    0.91477, Test    0.81032\n",
      "Epoch 12000: Train    0.92837, Test    0.81353\n",
      "Epoch 13000: Train    0.94278, Test    0.81913\n",
      "Epoch 14000: Train    0.91957, Test    0.81232\n",
      "Epoch 15000: Train    0.92677, Test    0.81353\n",
      "Epoch 16000: Train    0.92237, Test    0.82313\n",
      "Epoch 17000: Train    0.95598, Test    0.83713\n",
      "Epoch 18000: Train    0.95078, Test    0.82593\n",
      "Epoch 19000: Train    0.96319, Test    0.84674\n",
      "Epoch 20000: Train    0.95238, Test    0.82753\n"
     ]
    }
   ],
   "source": [
    "SGD_train(train, ne, nb, alpha, lam=0.0001, log_interval=1000, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 30)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Reference) Another Version\n",
    "Update weights and biases by each image data. (not taking summation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl = 2\n",
    "nh = 30\n",
    "ne = 30\n",
    "nb = 300\n",
    "alpha = 0.1\n",
    "lam = 0.0001\n",
    "output_type = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "layers = [train[0][0].shape[0]] + [nh]*nl + [train[0][1].shape[0]]\n",
    "L = len(layers)\n",
    "biases = [np.random.randn(n, 1) for n in layers[1:]] # input layer以外で必要. sizeが((30,1),(30,1),(10,1))のlist of lists.\n",
    "weights = [np.random.randn(n, m) for (m, n) in zip(layers[:-1], layers[1:])] # 長さmの縦長行列を長さnに変換する。sizeは((784,30),(30,30),(30,10)).\n",
    "deltas = [np.zeros((n, 1)) for n in layers] # ((784,1),(30,1),(30,1),(10,1))\n",
    "z_list = [np.zeros((n, 1)) for n in layers] # ((784,1),(30,1),(30,1),(10,1)). input layerは不要だけど簡単化のためつけている。\n",
    "a_list = [np.zeros((n, 1)) for n in layers] # ((784,1),(30,1),(30,1),(10,1))\n",
    "\n",
    "def SGD_train(train, ne, nb, alpha, lam = 0.0, log_interval=10, test=None):\n",
    "    \"\"\"SGD for training parameters\n",
    "    If verbose is set, print progressive accuracy updates.\n",
    "    If test set is provided, routine will print accuracy on test set as learning evolves\n",
    "    \"\"\"\n",
    "    for epoch in range(ne):\n",
    "        if epoch % log_interval == 0:\n",
    "            log_train_progress(train, test, epoch)\n",
    "        batch = random.sample(range(0, len(train)), nb)\n",
    "        for sample in batch:\n",
    "            SGD_step(*train[sample], alpha, lam) # *があるのは、trainはimageとlabelの二つセットだから\n",
    "\n",
    "def SGD_step(x, y, alpha, lam):\n",
    "    \"\"\"get gradients with x, y and do SGD on weights and biases\n",
    "    Args:\n",
    "        x: single sample features. (= image data)\n",
    "        y: single sample target. (= one-hot array of label)\n",
    "    \"\"\"\n",
    "    forward_back_prop(x, y)\n",
    "    for l in range(L-1):\n",
    "        biases[l] -= alpha * deltas[l+1]\n",
    "        weights[l] -= alpha * (np.dot(deltas[l+1], a_list[l].T) + lam * weights[l])\n",
    "\n",
    "def forward_back_prop(x, y):\n",
    "    \"\"\"Forward & back propagation for derivatives of C wrt parameters\"\"\"\n",
    "    a_list[0] = x\n",
    "\n",
    "    # Feedforward\n",
    "    for l in range(1, L):\n",
    "        z_list[l] = np.dot(weights[l-1], a_list[l-1]) + biases[l-1]\n",
    "        if l == L-1 and output_type == 0:\n",
    "            a_list[l] = softmax(z_list[l])\n",
    "        else:\n",
    "            a_list[l] = sigmoid(z_list[l])\n",
    "\n",
    "    # Output Error\n",
    "    if output_type == 1:\n",
    "        deltas[L-1] = grad_cost(a_list[L-1], y) * sigmoid_prime(z_list[L-1])\n",
    "    else:\n",
    "        deltas[L-1] = delta_cross_entropy(a_list[L-1], y)\n",
    "\n",
    "    # Back propagate\n",
    "    for l in range(L-2, -1, -1): # layerはoutputの後から遡っていく。L=4ならlayer=2,1,0\n",
    "        deltas[l] = np.dot(weights[l].T, deltas[l+1]) * sigmoid_prime(z_list[l])\n",
    "\n",
    "def grad_cost(a, y):\n",
    "    \"\"\"gradient of cost function. Assumes C(a,y) = (a-y)^2/2\"\"\"\n",
    "    return (a - y)\n",
    "\n",
    "def sigmoid(z, threshold=20):\n",
    "    z = np.clip(z, -threshold, threshold)\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z) * (1.0 - sigmoid(z))\n",
    "\n",
    "def softmax(z, overflow=False):\n",
    "    exp_z = np.exp(z)\n",
    "    if overflow:\n",
    "        exp_z = np.exp(z - np.max(z))\n",
    "    return exp_z / np.sum(exp_z)\n",
    "\n",
    "def delta_cross_entropy(p, y):\n",
    "    return (p - y)\n",
    "\n",
    "def forward_prop(a):\n",
    "    \"\"\"forward propagation for evaluate function only\"\"\"\n",
    "    for w, b in zip(weights, biases):\n",
    "        z = np.dot(w, a) + b\n",
    "        a = sigmoid(z)\n",
    "    return a\n",
    "\n",
    "def evaluate(data):\n",
    "    \"\"\"Evaluate current model on labeled train/test data\"\"\"\n",
    "    ctr = 0\n",
    "    for x, y in data:\n",
    "        yhat = forward_prop(x)\n",
    "        ctr += yhat.argmax() == y.argmax()\n",
    "    return float(ctr) / float(len(data))\n",
    "\n",
    "def log_train_progress(train, test, epoch):\n",
    "    \"\"\"Logs training progress\"\"\"\n",
    "    acc_train = evaluate(train)\n",
    "    if test is not None:\n",
    "        acc_test = evaluate(test)\n",
    "        print(\"Epoch {:4d}: Train {:10.5f}, Test {:10.5f}\".format(epoch, acc_train, acc_test))\n",
    "    else:\n",
    "        print(\"Epoch {:4d}: Train {:10.5f}\".format(epoch, acc_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0: Train    0.09844, Test    0.09764\n",
      "Epoch    1: Train    0.47339, Test    0.41817\n",
      "Epoch    2: Train    0.58824, Test    0.51220\n",
      "Epoch    3: Train    0.66827, Test    0.58463\n",
      "Epoch    4: Train    0.71909, Test    0.65026\n",
      "Epoch    5: Train    0.74110, Test    0.64746\n",
      "Epoch    6: Train    0.81232, Test    0.72829\n",
      "Epoch    7: Train    0.81072, Test    0.72109\n",
      "Epoch    8: Train    0.80432, Test    0.74110\n",
      "Epoch    9: Train    0.83713, Test    0.74710\n",
      "Epoch   10: Train    0.85714, Test    0.76591\n",
      "Epoch   11: Train    0.80992, Test    0.70468\n",
      "Epoch   12: Train    0.86835, Test    0.77911\n",
      "Epoch   13: Train    0.85394, Test    0.77151\n",
      "Epoch   14: Train    0.89116, Test    0.81593\n",
      "Epoch   15: Train    0.88715, Test    0.79952\n",
      "Epoch   16: Train    0.85914, Test    0.77631\n",
      "Epoch   17: Train    0.87835, Test    0.77031\n",
      "Epoch   18: Train    0.87875, Test    0.78151\n",
      "Epoch   19: Train    0.88395, Test    0.78551\n",
      "Epoch   20: Train    0.90556, Test    0.81513\n",
      "Epoch   21: Train    0.90956, Test    0.81473\n",
      "Epoch   22: Train    0.90396, Test    0.79832\n",
      "Epoch   23: Train    0.88675, Test    0.78591\n",
      "Epoch   24: Train    0.91437, Test    0.80712\n",
      "Epoch   25: Train    0.89556, Test    0.81072\n",
      "Epoch   26: Train    0.88635, Test    0.79032\n",
      "Epoch   27: Train    0.90316, Test    0.81713\n",
      "Epoch   28: Train    0.91357, Test    0.80912\n",
      "Epoch   29: Train    0.92957, Test    0.82433\n"
     ]
    }
   ],
   "source": [
    "SGD_train(train, ne, nb, alpha, lam=0.0001, log_interval=1, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "3457ecadf97be0fccb9de7706f11403121b070e4e02dbed6e7bd2aa524532334"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
